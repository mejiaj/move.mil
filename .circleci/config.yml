# Runs a set of CI jobs for Drupal 8 projects.

# Reusable steps.
## Defines images and working directory.
defaults: &defaults
  docker:
    - image: juampynr/drupal8ci:latest

    - image: selenium/standalone-chrome-debug:3.7.1-beryllium

    - image: mariadb:10.3
      environment:
        MYSQL_ALLOW_EMPTY_PASSWORD: 1

  working_directory: /var/www/html

## Defines the cache restoring mechanism.
restore_cache: &restore_cache
  # We use the composer.json as a way to determine if we can cache our build.
  keys:
  - v1-dependencies-{{ checksum "composer.json" }}
  # fallback to using the latest cache if no exact match is found
  - v1-dependencies-

## Defines the cache saving mechanism.
save_cache: &save_cache
  paths:
    - ./vendor
  key: v1-dependencies-{{ checksum "composer.json" }}

#Jobs
## Job to run Unit and Kernel tests.
unit_kernel_tests: &unit_kernel_tests
  <<: *defaults
  steps:
    - checkout
    - restore_cache: *restore_cache
    - run:
        name: Set up and run Unit and Kernel tests
        command: |
          apache2-foreground&
          robo install:dependencies
          robo setup:drupal || true
          cp .circleci/config/phpunit.xml web/core/
          mkdir -p artifacts/phpunit
          chmod -R 777 artifacts
          cd web
          sudo -E -u www-data ../vendor/bin/phpunit -c core --debug --verbose --log-junit ../artifacts/phpunit/phpunit.xml modules/custom
    - store_test_results:
        path: /var/www/html/artifacts/phpunit
    - store_artifacts:
        path: /var/www/html/artifacts
    - save_cache: *save_cache

## Job to run the update path and Behat tests.
behat_tests: &behat_tests
  <<: *defaults
  steps:
    - checkout
    - restore_cache: *restore_cache
    - run:
        name: Wait for the database service to be ready
        command: dockerize -wait tcp://localhost:3306 -timeout 1m
    - run:
        name: Install database and run the update path
        command: |
          robo install:dependencies
          robo setup:drupal || true
          cd web
          # For a quick start, set the following environment variable to a URL that contains
          # a database dump. Alternativelly, give CircleCI access to your development environment
          # and use Drush site aliases to run `drush sql-sync`.
          ../vendor/bin/drupal config:import -y -v --directory=../config/sync
          cd ..
    - save_cache: *save_cache
    - run:
        name: Set up and run Behat tests
        command: |
          apache2-foreground&
          cp .circleci/config/behat.yml tests/
          chown -R www-data:www-data /var/www/html/web/sites/default/files
          vendor/bin/behat --verbose -c tests/behat.yml
    - store_test_results:
        path: /var/www/html/artifacts/behat
    - store_artifacts:
        path: /var/www/html/artifacts

## Job to check coding standards.
code_sniffer: &code_sniffer
  <<: *defaults
  steps:
    - checkout
    - restore_cache: *restore_cache
    - run:
        name: Set up and inspect coding standards
        command: |
          robo install:dependencies
          vendor/bin/phpcs --config-set installed_paths vendor/drupal/coder/coder_sniffer
          mkdir -p artifacts/phpcs
          vendor/bin/phpcs --standard=Drupal --report=junit --report-junit=artifacts/phpcs/phpcs.xml web/modules/custom --ignore=*.min.js --ignore=*.min.css
          vendor/bin/phpcs --standard=DrupalPractice --report=junit --report-junit=artifacts/phpcs/phpcs.xml web/modules/custom --ignore=*.min.js --ignore=*.min.css
    - store_test_results:
        path: /var/www/html/artifacts/phpcs
    - store_artifacts:
        path: /var/www/html/artifacts
    - save_cache: *save_cache

## Job to check test coverage.
code_coverage: &code_coverage
  <<: *defaults
  steps:
    - checkout
    - restore_cache: *restore_cache
    - run:
        name: Set up and inspect code coverage
        environment:
          SIMPLETEST_BASE_URL: "http://localhost"
          SIMPLETEST_DB: "sqlite://localhost//tmp/drupal.sqlite"
          BROWSERTEST_OUTPUT_DIRECTORY: "/var/www/html/sites/simpletest"
        command: |
          robo install:dependencies
          robo setup:drupal || true
          cp .circleci/config/phpunit.xml web/core/
          mkdir -p artifacts/coverage-xml
          mkdir -p artifacts/coverage-html
          chmod -R 777 artifacts
          cd web
          timeout 60m sudo -E -u www-data ../vendor/bin/phpunit --verbose --debug -c core --coverage-xml ../artifacts/coverage-xml --coverage-html ../artifacts/coverage-html --testsuite nonfunctional modules/custom
          cd ../
          tar czf artifacts/coverage.tar.gz -C artifacts coverage-html coverage-xml
    - store_artifacts:
        path: /var/www/html/artifacts
    - save_cache: *save_cache

## Build stage image
build_stage_image: &build_stage_image
  docker:
    - image: python:3.6.6
  steps:
    - checkout
    - setup_remote_docker:
        docker_layer_caching: true
    - restore_cache: *restore_cache
    - run:
        name: Install dependencies
        command: |
          apt-get update \
            && apt-get install -y \
              unzip
    - run:
        name: Install Docker client
        command: |
          set -x
          VER="18.03.1-ce"
          curl -L -o /tmp/docker-$VER.tgz https://download.docker.com/linux/static/stable/x86_64/docker-$VER.tgz
          tar -xz -C /tmp -f /tmp/docker-$VER.tgz
          mv /tmp/docker/* /usr/bin
    - run:
        name: Install AWSCLI
        command: |
          curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
          unzip awscli-bundle.zip
          ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
    - run:
        name: Install AWS EB CLI
        command: |
          pip install awsebcli --upgrade --user
    - run:
        name: Python PATH
        command: |
            echo 'export PATH=$HOME/.local/bin:$PATH' >> $BASH_ENV
            source ~/.bashrc
    - run:
        name: "Log in to AWS ECR"
        command: eval $(aws ecr get-login --region us-east-1 --no-include-email)

    - run:
        name: "Build & Push Docker Image"
        command: |
          docker build -t $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/movemil:stage -f docker/Dockerfile .
          docker push $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/movemil:stage

## Build production Image
build_production_image: &build_production_image
  docker:
    - image: python:3.6.6
  steps:
    - checkout
    - setup_remote_docker:
        docker_layer_caching: true
    - restore_cache: *restore_cache
    - run:
        name: Install dependencies
        command: |
          apt-get update \
            && apt-get install -y \
              unzip
    - run:
        name: Install Docker client
        command: |
          set -x
          VER="18.03.1-ce"
          curl -L -o /tmp/docker-$VER.tgz https://download.docker.com/linux/static/stable/x86_64/docker-$VER.tgz
          tar -xz -C /tmp -f /tmp/docker-$VER.tgz
          mv /tmp/docker/* /usr/bin
    - run:
        name: Install AWSCLI
        command: |
          curl "https://s3.amazonaws.com/aws-cli/awscli-bundle.zip" -o "awscli-bundle.zip"
          unzip awscli-bundle.zip
          ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws
    - run:
        name: Install AWS EB CLI
        command: |
          pip install awsebcli --upgrade --user
    - run:
        name: Python PATH
        command: |
            echo 'export PATH=$HOME/.local/bin:$PATH' >> $BASH_ENV
            source ~/.bashrc
    - run:
        name: "Log in to AWS ECR"
        command: eval $(aws ecr get-login --region us-east-1 --no-include-email)

    - run:
        name: "Build & Push Docker Image"
        command: |
          docker build -t $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/movemil:production -f docker/Dockerfile .
          docker push $AWS_ACCOUNT_ID.dkr.ecr.us-east-1.amazonaws.com/movemil:production


# Declare all of the jobs we should run.
version: 2
jobs:
  behat:
    <<: *behat_tests
  code-sniffer:
    <<: *code_sniffer
  code-coverage:
    <<: *code_coverage
  build-stage-image:
    <<: *build_stage_image
  build-production-image:
    <<: *build_production_image

# Declare a workflow that runs all of our jobs in parallel.
workflows:
  version: 2
  test_and_lint:
    jobs:
      - behat
      - code-sniffer
      - code-coverage
  build_stage_image:
    jobs:
      - build-stage-image:
          filters:
            branches:
              only: 1.x-dev
  build_production_image:
    jobs:
      - build-production-image:
          filters:
            branches:
              only: master